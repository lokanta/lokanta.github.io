---    
layout: post    
title: how to build a government out of ai    
author: Bhante Sujato    
blurb: How the tech oligarchs will realize their dream of replacing government with machines. 
---    
    
- Written in Germany, November 2024    
- Global Atmospheric CO2: 424 ppm   
- Temperature record while writing this essay: highest November minimum in Germany, 17.8 ℃. 

It has been clear for a long time that the tech community wants to replace government with AI. That this will happen is an article of faith, a resigned (or hopeful) “when” rather than “if”. We are now far enough down the road to catch a glimpse of how they will do it—or try to. 

Already governments are primed to accept their machine overlords. They have tasted the sweet, sweet honey of tech money. More than that, governments are mostly run by old men whose chief understanding of technology is to realize that they don’t understand it. They know, or think, that the tech guys are smarter, younger, better than they, the new generation that will replace them. 

Like most everyone else, they are liable to imagine that AI is smarter than they are, so they turn to AI to answer their problems. AI is a perfect government adviser, as it immediately offers plausible-sounding words whose factuality is of little concern. AI makes fools sound smart. Worse, it makes fools think they are smart.

Take Romania for example. 18 months ago, they announced a new government advisory AI named Ion, which apparently scanned social media to tell the government about the sentiment of the Romanian people. Of course, what it would gather from this is the sentiment of those Romanian people who use social media. That is, insofar as it was reading the words of people at all, as the majority of social media content is made by AI. 

At the time, [Romanian PM Nicolae Ciuca said](https://www.theguardian.com/world/2023/mar/02/romania-ion-ai-government-honorary-adviser-artificial-intelligence-pm-nicolae-ciuca):

>I have the conviction that the use of AI should not be an option but an obligation to make better informed decisions.

A little over a year later and suddenly Romanian elections are dominated by an extreme right figure who popped out of nowhere, unknown to almost anyone until the current election cycle. 

Pundits on social media wonder where he came from, speculating that he is a Russian plant. [But the Guardian is surely correct to attribute his rise to the feckless leadership of mainstream parties](https://www.theguardian.com/world/2024/nov/25/calin-georgescu-romania-election-hard-right-candidate). Extremism may well be promoted by foreign powers, but it only finds a foothold in weak nations. 

His popularity is entirely due to his massive TikTok presence. TikTok was the first social media based on AI, its uncanny recommendations powered by AI ultimately trained on Chinese social media data. Romanian TikTok is full of bots, and there is little doubt that a massive AI disinformation campaign boosted his rankings.

So both sides are using AI, in very different ways. The incumbent is using AI for what it is marketed as, a reliable source of accurate information. The challenger is using AI for what it is actually good for, gaming attention and amplifying delusion. Guess who wins?

Far from improving governance, the use of AI merely highlighted the incapacity of current leadership, unable to take a step without consulting the machine. Did the use of AI pave the way for an extreme right takeover? Well, clearly it did not help. It was posited as the solution to problems, but those problems just got worse. It’s a pattern where the capacity of humans to lead humanity is continually eroded, and the solution, somehow, is always, “less humanity, more machines”. 

Underlying this is the long-term decline of democracy. A [2020 study found that](https://bigthink.com/the-present/future-of-democracy/):

>Between 1974 and 2005, a majority of states became democratic for the first time in history. However, a global democratic recession began in 2006 and has persisted – and deepened – over the past 14 years. Not only have average levels of freedom (or democratic quality) been declining globally and in most parts of the world, but the pace of democratic breakdown accelerated and the number of democratic transitions declined, particularly in the past five years.

The process is ongoing; the *Global State of Democracy 2024* study says, “[Declines in the quality of democracy continue to outnumber advances. One in four countries is moving forward, while four in nine are worse off](https://www.idea.int/gsod/2024/)”. 

“Democracy” is the “rule by the people”. When the people lose faith in humanity, they look to inhumanity for leadership: a brutal dictator, or, even better, a machine more soulless than any psychopath. 

While most governments do not have an official AI adviser, you can be sure that politicians, their assistants, their assistants’ assistants, the lobbyists, and the policymakers, are using AI to draft their reams of text and policy, to workshop their ideas, to evaluate hypotheses. 

In doing so, they not only reveal their collapsing faith in humanity, they advance it. No longer do they trust their own judgment, or the judgment of the people around them. They would rather listen to the unthoughts of a machine. “I could never write this well,” they muse, as the machine spits out yet another stream of statistically-determined, plagiarized unthought. They are content to be the editor and checker of machine dribble, serving its fancy, and every day finding that their role becomes less and less necessary.

We have seen a similar process unfold with smartphones. When they were introduced, people started developing new services and capabilities, offering new ways of paying for things, or identifying yourself, or verifying a service. As time went on, more people got phones, and providers started assuming that almost everyone has one. Other methods were neglected, and ultimately only the phone was left. We never really asked to live in a world where you need a phone to read a restaurant menu; it just kind of … happened. And now we throw away [15 million phones every day](https://www.bbc.com/news/science-environment-63245150).

Thousands of years ago in India, the brahmins discovered the power of advice. They would sit beside the king, giving him their sagely wisdom, educating him, drawing him from some choices towards other choices. And they could wield such power without themselves having to indulge in the dangerous and morally compromised act of war. Which is fine, kings need advisers. Hopefully they were good ones.

There is more than an incidental similarity between then and now, for the tech companies are mostly run by actual brahmins. Does this have any significance? Well, it points to the success of the brahmanical project, creating and sustaining moral, intellectual, and spiritual prestige while converting that to economic and political power. They’ve been doing that for three thousand years, and it’s obviously working. But it really highlights the extent to which technology entrenches privilege. Even what looks to an outsider like the success of an underprivileged group—immigrants from India—turns out to be an extension of millennia of privilege.

Governments have always had advisers. What has changed? One difference is that the advisers are machines, sure. But it’s more than that. It’s that the adviser is *the same machine*. There is, in effect, only one machine, and pretty much everything else is just a skin on top. So governments are no longer listening to advice from fellow citizens, from people living in their own country. *Every country is getting advice from the same machine*.

There are two senses in which this is true. Let me expand this a little.

Coding a modern AI model itself is straightforward. The limiting factors are the availability of three things.

1. Data
2. Energy
3. Processors

A large LLM requires the energy of a small nation, and is a massive drag on energy infrastructure. This is because it requires massive fields of servers, housed in giant warehouses, full of expensive processors running at full speed for months at a time. The cost of this is in the order of billions of dollars, so it will forever remain in the hands of a few massive corporations. This is not something that can be optimized away; we have been optimizing chips and energy production for a long time now, and can fairly accurately predict how they will improve in future. 

Nor should such capabilities be available to just anyone. [The environmental cost of AI is staggering](https://www.nature.com/articles/d41586-024-00478-x): the energy, the water usage, the land displacement, the minerals mined for the chips and other infrastructure, and much more.

LLMs at this scale will, for the forseeable future, be monopolized in the hands of a few corporations. We have seen how technology rapidly tends towards monopolization. Have you tried buying a phone recently? Did you enjoy trying the Firefox OS, or Ubuntu Touch, or Nokia’s Symbian, or Samsung’s Tizen, or Palm’s webOS, or Blackberry OS, or Microsoft’s Windows Mobile? Or did you choose between iOS and Android, between a 3.5 trillion dollar company and a 2 trillion dollar company? All those operating systems lost in time, like tears in rain. This tendency is true even in fields where scale is not needed—how much more so in a field where scale is the defining feature?

Currently there are a few large players in the field, but over the next few years this will be winnowed down as the biggest players strive to outperform their competition the only way they know how, by throwing even more money at the problem. (I say “forseeable future” out of an abundance of caution, as it is theoretically possible that a new kind of technology will emerge that surmounts these problems; but no such technology exists or is in serious development.)

There is a deeper sense in which even this modest differentiation is an illusion. Far and away the most important factor in determining the capabilities of an LLM is the data. The differences in the way the model is constructed and run are relatively trivial; they affect the manner of operation, not the underlying capabilities. The data used by these LLMs is not public, since AI companies arrogate to themselves the right to take everyone else’s data but not share their own data. But so far as we know, they are basically using all the data that they can get their hands on. There are obviously massive overlaps in the data between the different AIs, which is why the basic capabilities of the major AI models are similar. It cannot be otherwise. 

Thus for the forseeable future all major LLMs will use much of the same underlying data and therefore be essentially variations on a theme. The same pseudointelligence offering the same pseudoadvice to every government in the world. 

This is how AI is a fundamentally totalitarian technology. It only works because of scale, and only a vanishingly few people can afford the scale to build a modern LLM. Which means the power of advising the world’s governments will increasingly fall in the hands of a few machines, and those machines are in the hands of a few men. The character of those men—whose ranks include narcissists, fascists, misogynists, and [abusers](https://allhumansarehuman.medium.com/how-we-do-anything-is-how-we-do-everything-d2e5ca024a38)—shapes and informs their work at every level. 

This is the world as it is. It will keep going down this road, especially as a new generation enters the government, the tail end of Gen Z who have been brought up by AI. To them, asking AI for advice on government policy will be as natural as breathing. 

With the latest US election, the AI overlords Peter Thiel and Elon Musk have gone even further than I would have guessed a few months ago. They will wield a decisive influence on the next administration through their sponsorship of the winning party, and through their proxy, the incoming VP, J.D. Vance. 

Musk wants to start his Department of Government Efficiency. Who knows if it will happen, but the outlines of what they want it to do are becoming apparent.

It’s got nothing to do with efficiency, obviously. The idea, it seems, is to put a DOGE official in every government department to make assessments. What I expect to happen is that they’ll use an AI to winnow out the “essential” workers and get rid of the rest. 

Musk sacked 80% of Twitter staff when he took over, especially those tasked with ensuring safety and ethical usage. With their departure the place was overrun by Nazis and bots, which, it now seems clear, was the plan all along. It’s what they meant by “free speech”. It seems equally clear that the same plan will now be applied to the US government. This should be of utmost concern to every person. After all, Twitter sends messages, but the US sends bombs.

They’ll claim to use AI to replace the “unnecessary” workers. I’m feeling pretty good about predicting that this will go just as great as Romania’s AI. From the start, government will be hugely impacted and many services will fail altogether. 

Meanwhile, with the government “savings” they will then grant even more tax cuts to the rich in order to “balance the budget”. Curiously, the budget will get even further out of balance as money flows into the coffers of the AI overlords. It is widely underappreciated how much of Elon Musk’s wealth is due to his ability to [convince governments to give him money](https://www.latimes.com/business/la-fi-hy-musk-subsidies-20150531-story.html). 

The benefactors will include other oligarchs as well, especially the military. The growing role of AI in the military is just as dangerous as it is in government. It’s the same companies, the same players, the same fascists and psychopaths, who are supplying the tech that pilots drones or targets missiles. 

As the military becomes more dependent on AI, it will inevitably become more dependent on the men running AI. And as multiple governments deploy competing AI systems, they will engage, machine to machine, in an escalating gameplay of one-upmanship, in which genocide will be a mere side effect. The machines won’t care. And their overlords will reassure us that, if only we grant them more power, their machines will make sure the white side wins. Sorry, did I say “white” side? I meant “right” side, that was totally my bad! 

Thus the downward spiral accelerates: government gets worse, so its capacity to improve is undermined, so more AI is used, which makes it worse still. The enshittification of government. 

When it gets too bad, will people get that they have been hoodwinked, and realize that humans must remain forever the agents of human destiny? Some, surely. But I fear it will be too late, and perhaps not even then. Rather, the sentiment will shift to, “Who even needs a government anyway? [What has the government ever done for us?](https://www.youtube.com/watch?v=ExWfh6sGyso)” So we will replace the very idea of government with a fantasy of machine utopia. 

Let us march crisply towards our glorious future, “[all watched over by machines of loving grace](https://web.archive.org/web/20211125232026/http://www.brautigan.net/graphics/machines/machines-loudspeaker.gif)”. Of course, it won’t be “our” future, exactly. We will be just another inefficiency, soon to be optimized away, or retained only [at the pleasure of the machine](https://en.wikipedia.org/wiki/I_Have_No_Mouth%2C_and_I_Must_Scream). 

Perhaps the saddest part of all this is that, as far as Musk’s plans go, it’s all a side issue. It’s not that he wants to create a fascist authoritarian state on earth, particularly. He wants to colonize Mars. And to that end, as he has said many times, he must get rid of [EPA restrictions](https://www.npr.org/2024/10/10/nx-s1-5145776/spacex-texas-wetlands) on his Starship program. [That’s why he is doing what he is doing](https://www.eenews.net/articles/trump-musk-head-to-site-of-spacex-permit-problems/): don’t be distracted. 

I realize it’s unfashionable to like normal things, but it is a fact that for centuries people fought and died so that we could enjoy democracy. They bled oceans as humanity blundered on in our violent, messy way, towards a concept of a state that actually works. I’m no great fan of the nation-state idea as such, but since that is what we have, we should recognize that it is quite possible to run a nation in a reasonably okay way. We were doing it long before AI. 

Sure there are problems, but the biggest threat to a well-functioning state is always the same: the corrupting power of the rich. States function well when they rein in that power, moderate inequality, and ensure that the benefits of the work done by people go to the people. They tend towards autocracy, or fall apart completely, when the power of the rich is unfettered. 

The core [neoliberal strategy](https://www.theguardian.com/books/2016/apr/15/neoliberalism-ideology-problem-george-monbiot) has always been to undermine faith in government, for a well-functioning government acts in the public good, not in the interests of the rich. AI has become the perfect instrument to achieve this aim, as it works by undermining faith in humanity. No nation became better off by transferring wealth to the rich—but that is exactly what AI is accelerating. We can now envisage a world where there is not just small government, but no government at all. Only the machines matter. 

Make no mistake: those machines answer not to the common good, to reason, or to humanity. They answer only to the wills of their masters. Governance by AI means governance by tech oligarchs. We are sleep-walking into a future of global machine totalitarianism, oohing and aahing over their toys as their dreams play on the lids of our own serenely closed eyes.

Can we stop it? For a little while. So long as government remains in the hands of humans, we can pass our own laws. I think we should impose a strict size limit on LLM data; say 1TB. Then impose a limit on how much energy can be used. Let that be ratcheted down each year. If they’re so smart, let them do what billions of poor people manage to do every day—more with less. 

That’s just one idea. Maybe it’s not enough. Every day that passes, I look at the trees and breathe in the air, and a full-on Butlerian Jihad seems more and more appealing. Let us not make machines in the likeness of a human mind. 

